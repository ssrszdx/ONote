分类，聚类，线性回归

验证集，训练集

损失函数，

分类和标签

奖励模型和惩罚模型

1、查看cuda版本，torch版本

```text
nvidia-smi

#print(torch.__version__) 查看torch版本
```

  

![](https://pic1.zhimg.com/v2-9665423bc728ea50f7c55b47c559b83c_b.jpg)

![](https://pic2.zhimg.com/v2-291ad387d11dd020ff0e09f1801cbbfd_b.jpg)

2、查看torch是否可用cuda：

```text
torch.cuda.is_available()
```

查看GPU数量：

```text
torch.cuda.device_count()
```

查看当前GPU索引号（从0开始）：

```text
torch.cuda.current_device()
```

根据索引号查看GPU名字：

```text
torch.cuda.get_device_name(#输入索引号)
```

  

3、torch.tensor存储在GPU上

使用.cuda()可以将内存中的Tensor转换到GPU上。如果有多块GPU，可以使用.cuda(i)来表示第i块GPU所对应的显存（从0开始），cuda(0)和cuda()等价：

```text
a=torch.tensor([[1,2,4],[4,32,3]])
a=a.cuda(0)
print(a)

#或者在创建tensor的时候就可以指定
#device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#a=torch.tensor([[1,2,4],[4,32,3]],device=device)
```

![](https://pic2.zhimg.com/v2-dfa3d45aaa3598c32a1d78832fb016f5_b.jpg)

  

4、模型放在GPU上计算

```text
#假设这里有一个transformer的模型
net=transformer()  #类的实例化
net.cuda()  #放在GPU上         
outputs = net(input)  #后面直接输入数据


#或者device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#net = transformer().to(device)
```